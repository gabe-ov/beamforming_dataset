{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Jupter com a utilização de PCA antes da RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ler os dados dos csv com os dados simulados contidos nas pastas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ler_csv_e_atribuir_classes_com_pca(diretorio, classe, n_components=10):\n",
        "    dados = []\n",
        "    for arquivo in os.listdir(diretorio):\n",
        "        if arquivo.endswith('.csv'):\n",
        "            caminho_arquivo = os.path.join(diretorio, arquivo)\n",
        "            df = pd.read_csv(caminho_arquivo, sep=';')\n",
        "            features = df.iloc[:, :-1]  # Extrair features para PCA\n",
        "            features_normalizadas = (features - features.mean()) / features.std()  # Normalização\n",
        "            pca = PCA(n_components=n_components)  # PCA\n",
        "            features_reduzidas = pca.fit_transform(features_normalizadas)  # Aplicar PCA\n",
        "            df_reduzido = pd.DataFrame(data=features_reduzidas, columns=[f'componente_{i}' for i in range(1, n_components + 1)])\n",
        "            df_reduzido['Classe'] = classe\n",
        "            dados.append(df_reduzido)\n",
        "    return pd.concat(dados, ignore_index=True)\n",
        "\n",
        "diretorio_antes = './bkp_datasets_model/antes'\n",
        "diretorio_depois = './bkp_datasets_model/depois'\n",
        "\n",
        "dados_antes = ler_csv_e_atribuir_classes_com_pca(diretorio_antes, classe=0)\n",
        "\n",
        "dados_depois = ler_csv_e_atribuir_classes_com_pca(diretorio_depois, classe=1)\n",
        "\n",
        "dados_combinados = pd.concat([dados_antes, dados_depois], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2310000, 11)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dados_combinados.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dimensões das sequências de características: (231, 10000, 10)\n",
            "Dimensões das sequências de rótulos: (231,)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def split_into_sequences(data, sequence_length=10000):\n",
        "    sequences = []\n",
        "    labels = []\n",
        "    for i in range(0, len(data), sequence_length):\n",
        "        sequence = data.iloc[i:i+sequence_length, :-1]  # Excluir a última coluna (classe)\n",
        "        label = data.iloc[i+sequence_length-1, -1]  # Última classe da sequência\n",
        "        sequences.append(sequence.values)\n",
        "        labels.append(label)\n",
        "    return np.array(sequences), np.array(labels)\n",
        "\n",
        "X_sequences, y_sequences = split_into_sequences(dados_combinados)\n",
        "\n",
        "print(\"Dimensões das sequências de características:\", X_sequences.shape)\n",
        "print(\"Dimensões das sequências de rótulos:\", y_sequences.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Separar e verificar as dimensões dos dados de treinamento e teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dimensões dos dados de treinamento de características: (184, 10000, 10)\n",
            "Dimensões dos dados de teste de características: (47, 10000, 10)\n",
            "Dimensões dos dados de treinamento de rótulos: (184,)\n",
            "Dimensões dos dados de teste de rótulos: (47,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Dividir os dados em conjuntos de treinamento e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_sequences, y_sequences, test_size=0.2, random_state=42)\n",
        "\n",
        "# Verificar as dimensões dos dados de treinamento e teste\n",
        "print(\"Dimensões dos dados de treinamento de características:\", X_train.shape)\n",
        "print(\"Dimensões dos dados de teste de características:\", X_test.shape)\n",
        "print(\"Dimensões dos dados de treinamento de rótulos:\", y_train.shape)\n",
        "print(\"Dimensões dos dados de teste de rótulos:\", y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Realização do treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6930 - accuracy: 0.5185\n",
            "Epoch 1: val_accuracy improved from -inf to 0.46023, saving model to model_checkpoint_pca_ger.h5\n",
            "22/22 [==============================] - 110s 5s/step - loss: 0.6930 - accuracy: 0.5185 - val_loss: 0.6989 - val_accuracy: 0.4602\n",
            "Epoch 2/10\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6854 - accuracy: 0.5582\n",
            "Epoch 2: val_accuracy improved from 0.46023 to 0.52841, saving model to model_checkpoint_pca_ger.h5\n",
            "22/22 [==============================] - 110s 5s/step - loss: 0.6854 - accuracy: 0.5582 - val_loss: 0.6947 - val_accuracy: 0.5284\n",
            "Epoch 3/10\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6754 - accuracy: 0.5980\n",
            "Epoch 3: val_accuracy did not improve from 0.52841\n",
            "22/22 [==============================] - 113s 5s/step - loss: 0.6754 - accuracy: 0.5980 - val_loss: 0.6981 - val_accuracy: 0.5114\n",
            "Epoch 4/10\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6605 - accuracy: 0.6136\n",
            "Epoch 4: val_accuracy improved from 0.52841 to 0.55682, saving model to model_checkpoint_pca_ger.h5\n",
            "22/22 [==============================] - 111s 5s/step - loss: 0.6605 - accuracy: 0.6136 - val_loss: 0.6889 - val_accuracy: 0.5568\n",
            "Epoch 5/10\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6392 - accuracy: 0.6278\n",
            "Epoch 5: val_accuracy improved from 0.55682 to 0.57386, saving model to model_checkpoint_pca_ger.h5\n",
            "22/22 [==============================] - 111s 5s/step - loss: 0.6392 - accuracy: 0.6278 - val_loss: 0.6836 - val_accuracy: 0.5739\n",
            "Epoch 6/10\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6219 - accuracy: 0.6392\n",
            "Epoch 6: val_accuracy improved from 0.57386 to 0.59659, saving model to model_checkpoint_pca_ger.h5\n",
            "22/22 [==============================] - 112s 5s/step - loss: 0.6219 - accuracy: 0.6392 - val_loss: 0.6626 - val_accuracy: 0.5966\n",
            "Epoch 7/10\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.6028 - accuracy: 0.6648\n",
            "Epoch 7: val_accuracy improved from 0.59659 to 0.60795, saving model to model_checkpoint_pca_ger.h5\n",
            "22/22 [==============================] - 114s 5s/step - loss: 0.6028 - accuracy: 0.6648 - val_loss: 0.6599 - val_accuracy: 0.6080\n",
            "Epoch 8/10\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.5823 - accuracy: 0.6705\n",
            "Epoch 8: val_accuracy did not improve from 0.60795\n",
            "22/22 [==============================] - 113s 5s/step - loss: 0.5823 - accuracy: 0.6705 - val_loss: 0.6432 - val_accuracy: 0.5909\n",
            "Epoch 9/10\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.5711 - accuracy: 0.6903\n",
            "Epoch 9: val_accuracy improved from 0.60795 to 0.61364, saving model to model_checkpoint_pca_ger.h5\n",
            "22/22 [==============================] - 112s 5s/step - loss: 0.5711 - accuracy: 0.6903 - val_loss: 0.6406 - val_accuracy: 0.6136\n",
            "Epoch 10/10\n",
            "22/22 [==============================] - ETA: 0s - loss: 0.5628 - accuracy: 0.7216\n",
            "Epoch 10: val_accuracy did not improve from 0.61364\n",
            "22/22 [==============================] - 113s 5s/step - loss: 0.5628 - accuracy: 0.7216 - val_loss: 0.6437 - val_accuracy: 0.6080\n"
          ]
        }
      ],
      "source": [
        "checkpoint_path = \"model_checkpoint_pca_ger.h5\"\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(checkpoint_path, monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n",
        "\n",
        "model = Sequential([\n",
        "    LSTM(10, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "    LSTM(32),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2, callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "import h5py\n",
        "\n",
        "with h5py.File(checkpoint_path, 'r') as f:\n",
        "    best_model = tf.keras.models.load_model(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 2s 448ms/step - loss: 0.7464 - accuracy: 0.5532\n",
            "Acurácia do melhor modelo: 0.5531914830207825\n"
          ]
        }
      ],
      "source": [
        "loss, accuracy = best_model.evaluate(X_test, y_test)\n",
        "print(f'Acurácia do melhor modelo: {accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6/6 [==============================] - 4s 596ms/step - loss: 0.7288 - accuracy: 0.5489\n",
            "Acurácia do melhor modelo: 0.5489130616188049\n"
          ]
        }
      ],
      "source": [
        "loss, accuracy = best_model.evaluate(X_train, y_train)\n",
        "print(f'Acurácia do melhor modelo: {accuracy}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
